---
title: "Collaborative Filtering with recommenderlab."
output: html_document
---

They are a few different ways to build a recommender system. 

* User Based Collaborative Filtering : If my friend Jimmy tells me that he liked the movie 'Drive', I might like it too since we have similar tastes. This is called UBCF (User-based collaborative filtering). Another way to think about it is that this is soft-clustering. We find Users with similar tastes (neighbourhood) and use their preferences to build yours.

* Item Based Collaborative Filtering: If I watched 'Darjeeling Limited', I might be inclined to watch 'The Royal Tannenbaums' but not necessarily 'Die Hard'. This is because the first two are more similar in the users who have watched/rated them. This is a rather simple to compute as all we need is the covariance between products to find out what this might be.

```{r,warning=FALSE,message=FALSE}
install.packages("recommenderlab")
library(recommenderlab)
library(ggplot2)
```

Load the data we are going to work with.

```{r}
data(MovieLense)
MovieLense


head(as.data.frame(MovieLense))

# Visualizing a sample of this
image(sample(MovieLense, 500), main = "Raw ratings")

# Visualizing ratings
qplot(getRatings(MovieLense), binwidth = 1, 
      main = "Histogram of ratings", xlab = "Rating") # Skewed to the right
 
# How about after normalization?
# Normalization tries to reduce the individual rating bias by row centering the data, i.e., by subtracting from each available rating the mean of the ratings of that user (row). Z-score in addition divides by the standard deviation of the row/column. Normalization can also be done on columns.
qplot(getRatings(normalize(MovieLense, method = "Z-score")),
      main = "Histogram of normalized ratings", xlab = "Rating") # seems better
 
# How many movies did people rate on average
qplot(rowCounts(MovieLense), binwidth = 10, 
      main = "Movies Rated on average", 
      xlab = "# of users", 
      ylab = "# of movies rated")
 
# What is the mean rating of each movie
qplot(colMeans(MovieLense), binwidth = .1, 
      main = "Mean rating of Movies", 
      xlab = "Rating", 
      ylab = "# of movies")

```

```{r}

recommenderRegistry$get_entries(dataType = "realRatingMatrix")
# We have a few options
 
# Let's check some algorithms against each other
scheme <- evaluationScheme(MovieLense, method = "split", train = .9,
                           k = 1, given = 10, goodRating = 4)
scheme
 
algorithms <- list(
    "random items"  = list(name="RANDOM", param=list(normalize = "Z-score")),
    "popular items" = list(name="POPULAR", param=list(normalize = "Z-score")),
    "user-based CF" = list(name="UBCF", param=list(normalize = "Z-score",
                                                   method="Cosine",
                                                   nn=50)),
    "item-based CF" = list(name="IBCF", param=list(normalize = "Z-score"))
)

# run algorithms, predict next n movies
results_m <- evaluate(scheme, algorithms, n=c(1, 3, 5, 10, 15, 20))
 
# Draw ROC curve
plot(results_m, annotate = 1:4, legend="topleft")
 
# See precision / recall
plot(results_m, "prec/rec", annotate=3)
```

It seems like UBCF did better than IBCF. 
Predictably, RANDOM is the worst but perhaps surprisingly it seems, its hard to beat POPULAR. 
I guess we are not so different, you and I.



